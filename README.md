

# ğŸŒ‹ Advanced Retrieval-Augmented Generation (RAG) Pipeline  
### `Using Volcano wikipedia page`

This repository demonstrates a production-grade **Retrieval-Augmented Generation (RAG)** pipeline designed for high-precision information extraction. While this implementation uses Wikipedia's "Volcano" article as a test case, the architecture is **domain-agnostic** and built to handle any complex unstructured text.

Unlike basic vector search demos, this system incorporates **semantic data cleaning, metadata-aware chunking, and second-stage reranking** to significantly improve answer precision and reduce hallucinations.

---

## ğŸ§  System Architecture

```python
Wikipedia Page
â†“
Targeted HTML Parsing (BeautifulSoup)
â†“
Noise Removal & Text Normalization
â†“
Semantic Chunking + Metadata
â†“
Dense Vector Embeddings (MiniLM)
â†“
FAISS Vector Search (Top-K)
â†“
Cross-Encoder Reranking (FlashRank)
â†“
LLM Answer Generation (GPT-4o)
```

---

## ğŸ¯ Problems This Project Solves

### 1. Noisy Data Ingestion
Raw HTML scraping often introduces:
- Citation markers (`[1]`, `[24]`)
- Edit tags
- Navigation and layout artifacts

These tokens pollute embedding space and degrade retrieval quality.

**Solution:**  
```python
Targeted DOM parsing + regex-based lexical cleaning before embedding.
```

---

### 2. Context Fragmentation
Naive fixed-size chunking can split ideas mid-sentence.

**Solution:**  
`RecursiveCharacterTextSplitter` with overlap preserves semantic continuity while remaining token-efficient.

---

### 3. Low-Precision Top-K Retrieval
Cosine similarity alone does not guarantee that retrieved chunks *actually answer the question*.

**Solution:**  
A **two-stage retrieval pipeline**:
- FAISS for recall
- FlashRank (cross-encoder) for precision

---

## ğŸ› ï¸ Technical Stack

| Component | Technology |
|--------|-----------|
| Data Source | Wikipedia |
| HTML Parsing | BeautifulSoup + SoupStrainer |
| Chunking | LangChain RecursiveCharacterTextSplitter |
| Embeddings | `all-MiniLM-L6-v2` |
| Vector Store | FAISS |
| Reranking | FlashRank |
| LLM | OpenAI GPT-4o |
| Framework | LangChain (modern v0.3 style) |

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Sohan-bhatt/Reranked-Context-Pipeline.git
cd volcano-rag
````

### 2ï¸âƒ£ Create Environment & Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure Environment Variables

Create a `.env` file:

```env
OPENAI_API_KEY=your_api_key_here
```


---

## ğŸ” Example Query

```python
"What are the long-term environmental impacts of volcanic eruptions?"
```



## ğŸ“Œ Key Takeaway

This project demonstrates how **careful preprocessing, retrieval design, and reranking** can dramatically outperform naÃ¯ve RAG systems â€” even when using the same LLM.

It is designed as a **scalable foundation** for real-world research assistants.


